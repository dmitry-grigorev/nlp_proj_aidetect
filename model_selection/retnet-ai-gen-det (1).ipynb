{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10268139,"sourceType":"datasetVersion","datasetId":6352740}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install git+https://github.com/fkodom/yet-another-retnet.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:45:52.970843Z","iopub.execute_input":"2025-01-12T11:45:52.971166Z","iopub.status.idle":"2025-01-12T11:46:08.798865Z","shell.execute_reply.started":"2025-01-12T11:45:52.971142Z","shell.execute_reply":"2025-01-12T11:46:08.797026Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/fkodom/yet-another-retnet.git\n  Cloning https://github.com/fkodom/yet-another-retnet.git to /tmp/pip-req-build-0gsbz68o\n  Running command git clone --filter=blob:none --quiet https://github.com/fkodom/yet-another-retnet.git /tmp/pip-req-build-0gsbz68o\n  Resolved https://github.com/fkodom/yet-another-retnet.git to commit fdd1c0e85a5ee64d4556c731879ee5efab9a968a\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet==0.5.1) (0.8.0)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from yet-another-retnet==0.5.1) (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->yet-another-retnet==0.5.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->yet-another-retnet==0.5.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->yet-another-retnet==0.5.1) (1.3.0)\nBuilding wheels for collected packages: yet-another-retnet\n  Building wheel for yet-another-retnet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for yet-another-retnet: filename=yet_another_retnet-0.5.1-py3-none-any.whl size=406883 sha256=d4e65fda56ee21951587592b982308397868cd49f9b7378d7f25881d0938c9c1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8fhontav/wheels/23/1c/61/6971408ed03a8c880915076e3008802b3feeafb157cac9b28f\nSuccessfully built yet-another-retnet\nInstalling collected packages: yet-another-retnet\nSuccessfully installed yet-another-retnet-0.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom transformers import DistilBertTokenizer, DistilBertModel\n#from datasets import Dataset\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers.pipelines.pt_utils import KeyDataset\nfrom tqdm import tqdm\nimport pandas as pd\n\nfrom yet_another_retnet.retnet import RetNet\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:46:08.801036Z","iopub.execute_input":"2025-01-12T11:46:08.801428Z","iopub.status.idle":"2025-01-12T11:46:08.874320Z","shell.execute_reply.started":"2025-01-12T11:46:08.801397Z","shell.execute_reply":"2025-01-12T11:46:08.873114Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.random.manual_seed(0)\n\ntokenizer = AutoTokenizer.from_pretrained('gpt2')\n\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nmodel = RetNet(\n    num_tokens=len(tokenizer), # vocab size, usually taken from tokenizer\n    d_model=192, #embedding dimension\n    dim_feedforward = 384,\n    nhead=4,\n    num_layers=8,\n    device=device)\n\nmodel_q = RetNet(\n    num_tokens=len(tokenizer), # vocab size, usually taken from tokenizer\n    d_model=192, #embedding dimension\n    dim_feedforward = 384,\n    nhead=1,\n    num_layers=3,\n    device=device)\n\n#retnet_1_3b(num_tokens=len(tokenizer), device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:46:08.876512Z","iopub.execute_input":"2025-01-12T11:46:08.876987Z","iopub.status.idle":"2025-01-12T11:46:09.903565Z","shell.execute_reply.started":"2025-01-12T11:46:08.876941Z","shell.execute_reply":"2025-01-12T11:46:09.902176Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:46:09.905072Z","iopub.execute_input":"2025-01-12T11:46:09.905384Z","iopub.status.idle":"2025-01-12T11:46:09.914650Z","shell.execute_reply.started":"2025-01-12T11:46:09.905353Z","shell.execute_reply":"2025-01-12T11:46:09.913863Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"RetNet(\n  (embedding): Embedding(50258, 192)\n  (decoder): RetNetDecoder(\n    (layers): ModuleList(\n      (0-7): 8 x RetNetDecoderLayer(\n        (dropout): Dropout(p=0.1, inplace=False)\n        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n        (retention): MultiScaleRetention(\n          (q_proj): Linear(in_features=192, out_features=192, bias=True)\n          (k_proj): Linear(in_features=192, out_features=192, bias=True)\n          (v_proj): Linear(in_features=192, out_features=192, bias=True)\n          (group_norm): GroupNorm(4, 192, eps=1e-06, affine=False)\n          (g_proj): Linear(in_features=192, out_features=192, bias=True)\n          (out_proj): Linear(in_features=192, out_features=192, bias=True)\n        )\n        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n        (linear1): Linear(in_features=192, out_features=384, bias=True)\n        (linear2): Linear(in_features=384, out_features=192, bias=True)\n      )\n    )\n  )\n  (out): Linear(in_features=192, out_features=50258, bias=True)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_test_data = pd.read_csv('/kaggle/input/human-vs-qwen25-n-phi3/train_test_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:36:11.343658Z","iopub.execute_input":"2025-01-03T13:36:11.343951Z","iopub.status.idle":"2025-01-03T13:36:13.192301Z","shell.execute_reply.started":"2025-01-03T13:36:11.343925Z","shell.execute_reply":"2025-01-03T13:36:13.191334Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.parameters()):\n        nn=1\n        for s in list(p.size()):\n            nn = nn*s\n        pp += nn\n    return pp\nget_n_params(model.decoder), get_n_params(model_q.decoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:46:12.776391Z","iopub.execute_input":"2025-01-12T11:46:12.776850Z","iopub.status.idle":"2025-01-12T11:46:12.786315Z","shell.execute_reply.started":"2025-01-12T11:46:12.776819Z","shell.execute_reply":"2025-01-12T11:46:12.785057Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2672640, 1002240)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\n\n\ndef enable_determinism():\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n    torch.use_deterministic_algorithms(True)\n\ndef fix_seeds(seed: int):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.mps.manual_seed(seed)\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\nenable_determinism()\nfix_seeds(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:36:13.201596Z","iopub.execute_input":"2025-01-03T13:36:13.201884Z","iopub.status.idle":"2025-01-03T13:36:13.223154Z","shell.execute_reply.started":"2025-01-03T13:36:13.201854Z","shell.execute_reply":"2025-01-03T13:36:13.222492Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Класс датасета\nclass AnswersDataset(Dataset):\n  def __init__(self, tokenizer, data_df, sampletype,  max_len=512):\n    self.raw_data = data_df[data_df['sample_type']==sampletype]\n\n    self.max_len = max_len\n    self.tokenizer = tokenizer\n    self.inputs_q = []\n    self.inputs_a = []\n    \n    self.targets = []\n\n    self.class_mapper = {'Human': 0, 'Phi3-mini': 1, 'Qwen25': 2}\n\n    self.class_mapper_inv = {v: k for k, v in self.class_mapper.items()}\n\n    self._build()\n\n\n  def __len__(self):\n    return len(self.inputs_a)\n\n  def __getitem__(self, index):\n    question_ids = self.inputs_q[index].squeeze()\n    answers_ids = self.inputs_a[index].squeeze()\n\n\n    target_ids = self.targets[index]\n\n\n    return  question_ids, answers_ids, target_ids\n    #{\"question_ids\": question_ids, \"answers_ids\": answers_ids, \"target_ids\": target_ids}\n\n  def _build(self):\n    self._buil_examples_from_files()\n\n  def _buil_examples_from_files(self):\n    # REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()]\")\n    # REPLACE_WITH_SPACE = re.compile(\"()|(\\-)|(\\/)\")\n\n    for i, row in tqdm(self.raw_data.iterrows(), total=self.raw_data.shape[0]):\n\n      if pd.isna(row['Answers']):\n        continue\n\n      text_question = row['Question']\n      text_answer = row['Answers']\n\n      line_question = text_question.strip()\n      line_answer = text_answer.strip()\n\n\n      # line = REPLACE_NO_SPACE.sub(\"\", line)\n      # line = REPLACE_WITH_SPACE.sub(\"\", line)\n      # line = line + ' '\n\n      target = self.class_mapper[row['Author']]\n\n       # tokenize inputs\n      tokenized_questions, q_mask = [v for k, v in self.tokenizer.batch_encode_plus(\n          [line_question], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      ).items()]\n      tokenized_answers, a_mask = [v for k, v in self.tokenizer.batch_encode_plus(\n          [line_answer], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      ).items()]\n\n       # tokenize targets\n\n\n      self.inputs_q.append(tokenized_questions)\n      self.inputs_a.append(tokenized_answers)\n \n      self.targets.append(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:36:13.223876Z","iopub.execute_input":"2025-01-03T13:36:13.224166Z","iopub.status.idle":"2025-01-03T13:36:13.238938Z","shell.execute_reply.started":"2025-01-03T13:36:13.224139Z","shell.execute_reply":"2025-01-03T13:36:13.238055Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"max_seq_length = 128 # with 256 one epoch with 2 evaluations take 2 hours together\ntrain_dataset = AnswersDataset(tokenizer, train_test_data, 'train', max_len=max_seq_length)\n#test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\nval_dataset = AnswersDataset(tokenizer, train_test_data, 'val', max_len=max_seq_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:36:13.241033Z","iopub.execute_input":"2025-01-03T13:36:13.241257Z","iopub.status.idle":"2025-01-03T13:37:43.122129Z","shell.execute_reply.started":"2025-01-03T13:36:13.241237Z","shell.execute_reply":"2025-01-03T13:37:43.121193Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 67699/67699 [01:07<00:00, 995.90it/s] \n100%|██████████| 21233/21233 [00:21<00:00, 971.87it/s] \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"g = torch.Generator()\nbatch_size=128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g,\n                          pin_memory=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2)\n#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:37:43.123758Z","iopub.execute_input":"2025-01-03T13:37:43.124002Z","iopub.status.idle":"2025-01-03T13:37:43.128272Z","shell.execute_reply.started":"2025-01-03T13:37:43.123980Z","shell.execute_reply":"2025-01-03T13:37:43.127392Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model.decoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:37:43.129167Z","iopub.execute_input":"2025-01-03T13:37:43.129447Z","iopub.status.idle":"2025-01-03T13:37:43.144764Z","shell.execute_reply.started":"2025-01-03T13:37:43.129415Z","shell.execute_reply":"2025-01-03T13:37:43.144110Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"RetNetDecoder(\n  (layers): ModuleList(\n    (0-7): 8 x RetNetDecoderLayer(\n      (dropout): Dropout(p=0.1, inplace=False)\n      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n      (retention): MultiScaleRetention(\n        (q_proj): Linear(in_features=192, out_features=192, bias=True)\n        (k_proj): Linear(in_features=192, out_features=192, bias=True)\n        (v_proj): Linear(in_features=192, out_features=192, bias=True)\n        (group_norm): GroupNorm(4, 192, eps=1e-06, affine=False)\n        (g_proj): Linear(in_features=192, out_features=192, bias=True)\n        (out_proj): Linear(in_features=192, out_features=192, bias=True)\n      )\n      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n      (linear1): Linear(in_features=192, out_features=384, bias=True)\n      (linear2): Linear(in_features=384, out_features=192, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn as nn\nclass RetNetClf_FCtuned_ver2(nn.Module):\n    def __init__(self, max_seq_length=512):\n        super(RetNetClf_FCtuned_ver2, self).__init__()\n        self.rnmodel_ans = model\n        self.rnmodel_q = model_q.decoder\n\n        self.model_out_features =  model.decoder.layers[-1].linear2.out_features\n        self.dropout_rate = model.decoder.layers[-1].dropout.p\n\n        \n        self.model_q_out_entrance = torch.nn.Sequential(\n            torch.nn.Dropout(p=self.dropout_rate, inplace=False),\n            torch.nn.LayerNorm((self.model_out_features,), eps=1e-06, elementwise_affine=True)\n        )\n\n        self.retlayer_join_index = 1\n        \n        self.length=max_seq_length\n        self.fc = nn.Linear(in_features=self.length*self.model_out_features, out_features = 3)\n        self.activation = nn.Softmax(dim=1)\n        #self.freeze_layers()\n\n\n    def forward(self, qx, ax):\n        # parallel mode for training\n\n        q_emb = self.rnmodel_ans.embedding(qx)\n        a_emb = self.rnmodel_ans.embedding(ax)\n\n        rnout_a = a_emb\n        rnout_q = self.rnmodel_q.forward_parallel(q_emb)\n        for layer in self.rnmodel_ans.decoder.layers[:self.retlayer_join_index]:\n            rnout_a = layer.forward_parallel(rnout_a)\n\n        # now join question and answer in retention layer\n        join_layer = self.rnmodel_ans.decoder.layers[self.retlayer_join_index]\n        rnout_q = self.model_q_out_entrance(rnout_q)\n        rnout_a = join_layer.dropout(rnout_a)\n        rnout_a = join_layer.norm1(rnout_a)\n        retout = join_layer.retention.forward_parallel(rnout_q, rnout_a, rnout_a)[0]\n\n        retout = join_layer.norm2(retout)\n        retout = join_layer.linear1(retout)\n        retout = join_layer.linear2(retout)\n\n        # now the rest retention layers as usual\n        for layer in self.rnmodel_ans.decoder.layers[self.retlayer_join_index+1:]:\n            retout = layer.forward_parallel(retout)\n        #print(rnout_q.shape, rnout_a.shape)\n        \n        out = retout.reshape(retout.shape[0], -1)\n        pred = self.fc(out)\n\n        return self.activation(pred)\n\n\nclass RetNetClf_FCtuned_ver1(nn.Module):\n    def __init__(self, max_seq_length=512):\n        super(RetNetClf_FCtuned_ver1, self).__init__()\n        self.rnmodel_ans = model # some retention layers then join question and answer in one ret. layer\n        self.rnmodel_q = model_q.decoder\n\n        \n        self.model_out_features =  model.decoder.layers[-1].linear2.out_features\n\n        self.length=max_seq_length\n        self.fc = nn.Linear(in_features=2*self.length*self.model_out_features, out_features = 3)\n        self.activation = nn.Softmax()\n        #self.freeze_layers()\n\n\n    def forward(self, qx, ax):\n        # parallel mode for training\n\n        q_emb = self.rnmodel_ans.embedding(qx)\n        a_emb = self.rnmodel_ans.embedding(ax)\n        \n        rnout_q = self.rnmodel_q.forward_parallel(q_emb)\n        rnout_a = self.rnmodel_ans.decoder.forward_parallel(a_emb)\n\n        #print(rnout_q.shape, rnout_a.shape)\n        concat = torch.concatenate([rnout_q, rnout_a], axis=1)\n        out = concat.reshape(concat.shape[0], -1)\n        pred = self.fc(out)\n\n        return self.activation(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:47:00.142214Z","iopub.execute_input":"2025-01-12T11:47:00.142626Z","iopub.status.idle":"2025-01-12T11:47:00.160477Z","shell.execute_reply.started":"2025-01-12T11:47:00.142595Z","shell.execute_reply":"2025-01-12T11:47:00.158993Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#model1 = RetNetClf_FCtuned(max_seq_length)\nmodel_1, model_2 = RetNetClf_FCtuned_ver1(max_seq_length), RetNetClf_FCtuned_ver2(max_seq_length)\nget_n_params(model_1.rnmodel_ans)+get_n_params(model_1.rnmodel_q)+get_n_params(model_1.fc), get_n_params(model_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:49:32.934545Z","iopub.execute_input":"2025-01-12T11:49:32.935017Z","iopub.status.idle":"2025-01-12T11:49:32.948171Z","shell.execute_reply.started":"2025-01-12T11:49:32.934985Z","shell.execute_reply":"2025-01-12T11:49:32.947032Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(23171669, 23171669)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"get_n_params(model_2.rnmodel_ans)+get_n_params(model_2.rnmodel_q)\\\n+get_n_params(model_2.model_q_out_entrance)+get_n_params(model_2.fc), get_n_params(model_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:51:59.610477Z","iopub.execute_input":"2025-01-12T11:51:59.610888Z","iopub.status.idle":"2025-01-12T11:51:59.619389Z","shell.execute_reply.started":"2025-01-12T11:51:59.610857Z","shell.execute_reply":"2025-01-12T11:51:59.618363Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(23098325, 23098325)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"!pip install torcheval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:37:43.162554Z","iopub.execute_input":"2025-01-03T13:37:43.162841Z","iopub.status.idle":"2025-01-03T13:37:46.895030Z","shell.execute_reply.started":"2025-01-03T13:37:43.162814Z","shell.execute_reply":"2025-01-03T13:37:46.894130Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torcheval.metrics.functional import multiclass_confusion_matrix as conf_matrix\n\ndef evaluation_epoch(model, loader, loss_obj):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y = chunk\n      pred = model(qx.to(device), ax.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': total_loss/n_total,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}\n\ndef train_neural_net(model, train_loader, test_loader):\n  loss = nn.CrossEntropyLoss()\n  optimizer=torch.optim.Adam([{'params': model.rnmodel_ans.parameters()},\n                              {'params': model.rnmodel_q.parameters()},\n                              {'params': model.model_q_out_entrance.parameters()},\n                              {'params': model.fc.parameters()}], lr=1e-4)\n  n_epochs=8\n  loss_train_history = [] # логируется всегда\n\n  # логируются каждую эпоху\n\n  train_epoch_evals = []\n  test_epoch_evals = []\n\n  for _ in range(n_epochs):\n    i=0\n    model.train().to(device)\n    for train_chunk in tqdm(train_loader):\n        qx, ax, y = train_chunk\n        optimizer.zero_grad(set_to_none=True)\n\n\n        pred = model(qx.to(device), ax.to(device))\n        loss_val = loss(pred, y.to(device)) #.long()\n        loss_val.backward()\n\n        loss_val_item = loss_val.detach().cpu().item()\n\n        optimizer.step()\n        loss_train_history.append(loss_val_item)\n        i+=1\n        if i % 100 == 0:\n            print(f'train step {i}: train loss = {loss_val_item :.3f}')\n            #inspect retention weights\n            # for j, layer in enumerate(model.rnmodel_ans.decoder.layers):\n            #     if j == 0:\n            #         print('gradient:{}\\n----------\\n{}'.format(j,torch.norm(layer.retention.q_proj.weight.grad)))\n            # print('gradient:{}\\n----------\\n{}'.format(j,torch.norm(model.fc.weight.grad)))\n        #break\n\n    model.eval()\n    #model.cpu()\n\n    #train\n    print('train evaluation')\n    train_eval = evaluation_epoch(model, train_loader, loss)\n    print(f\"epoch {_}: train ava accuracy = {train_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: train loss = {train_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: train ovo accuracy = {train_eval['accuracy_ovo'] :.3f}\")\n    train_epoch_evals.append(train_eval)\n\n    #test\n    print('test evaluation')\n    test_eval = evaluation_epoch(model, test_loader, loss)\n    print(f\"epoch {_}: test ava accuracy = {test_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: test loss = {test_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: test ovo accuracy = {test_eval['accuracy_ovo'] :.3f}\")\n    test_epoch_evals.append(test_eval)\n\n  return {'training_loss_history': loss_train_history,\n          'train_epochs_res': train_epoch_evals,\n          'test_epochs_res': test_epoch_evals\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:37:46.896086Z","iopub.execute_input":"2025-01-03T13:37:46.896408Z","iopub.status.idle":"2025-01-03T13:37:47.774808Z","shell.execute_reply.started":"2025-01-03T13:37:46.896378Z","shell.execute_reply":"2025-01-03T13:37:47.774155Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model1 = RetNetClf_FCtuned_ver2(max_seq_length)\ntrain_hist = train_neural_net(model1, train_loader, val_loader) # потом перезапустить обучение Т5, т.к. забыл там активацию","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:37:47.775622Z","iopub.execute_input":"2025-01-03T13:37:47.775837Z","iopub.status.idle":"2025-01-03T14:09:53.418373Z","shell.execute_reply.started":"2025-01-03T13:37:47.775819Z","shell.execute_reply":"2025-01-03T14:09:53.417427Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/529 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n 19%|█▉        | 100/529 [00:28<01:57,  3.64it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.874\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [00:57<01:38,  3.34it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.942\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:29<01:18,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.879\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:04<00:43,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.871\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:37<00:09,  3.09it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.812\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:47<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:59<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: train ava accuracy = 0.717\nepoch 0: train loss = 0.832\nepoch 0: train ovo accuracy = 0.837\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: test ava accuracy = 0.704\nepoch 0: test loss = 0.846\nepoch 0: test ovo accuracy = 0.825\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:33<02:23,  3.00it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.783\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:06<01:51,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.900\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:39<01:15,  3.05it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.846\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:12<00:42,  3.04it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.896\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:44<00:09,  3.15it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.879\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:54<00:00,  3.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:58<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: train ava accuracy = 0.740\nepoch 1: train loss = 0.811\nepoch 1: train ovo accuracy = 0.846\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: test ava accuracy = 0.727\nepoch 1: test loss = 0.823\nepoch 1: test ovo accuracy = 0.836\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:32<02:18,  3.09it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.819\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:04<01:47,  3.07it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.784\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:36<01:13,  3.11it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.816\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:08<00:40,  3.19it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.794\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:40<00:09,  3.16it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.830\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:49<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:58<00:00,  9.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: train ava accuracy = 0.764\nepoch 2: train loss = 0.787\nepoch 2: train ovo accuracy = 0.867\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  9.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: test ava accuracy = 0.745\nepoch 2: test loss = 0.805\nepoch 2: test ovo accuracy = 0.857\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:31<02:09,  3.30it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.778\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:01<01:40,  3.27it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.790\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:33<01:11,  3.18it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.840\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:04<00:39,  3.29it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.825\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:34<00:08,  3.37it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.794\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:42<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:58<00:00,  9.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: train ava accuracy = 0.740\nepoch 3: train loss = 0.811\nepoch 3: train ovo accuracy = 0.856\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: test ava accuracy = 0.708\nepoch 3: test loss = 0.844\nepoch 3: test ovo accuracy = 0.843\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:30<02:09,  3.32it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.778\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:00<01:42,  3.20it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.762\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:30<01:08,  3.36it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.817\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:00<00:38,  3.36it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.825\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:30<00:08,  3.35it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.817\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:39<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:59<00:00,  8.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: train ava accuracy = 0.745\nepoch 4: train loss = 0.806\nepoch 4: train ovo accuracy = 0.882\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: test ava accuracy = 0.743\nepoch 4: test loss = 0.808\nepoch 4: test ovo accuracy = 0.877\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:30<02:10,  3.28it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.798\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:00<01:39,  3.29it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.801\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:30<01:09,  3.31it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.762\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [02:00<00:38,  3.35it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.853\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:30<00:08,  3.36it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.755\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:39<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:59<00:00,  8.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: train ava accuracy = 0.756\nepoch 5: train loss = 0.795\nepoch 5: train ovo accuracy = 0.882\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: test ava accuracy = 0.757\nepoch 5: test loss = 0.794\nepoch 5: test ovo accuracy = 0.884\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:29<02:07,  3.36it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.778\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [00:59<01:37,  3.37it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.801\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:29<01:07,  3.39it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.786\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [01:58<00:38,  3.39it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.864\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:28<00:08,  3.38it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.903\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:36<00:00,  3.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:58<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: train ava accuracy = 0.760\nepoch 6: train loss = 0.791\nepoch 6: train ovo accuracy = 0.872\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: test ava accuracy = 0.748\nepoch 6: test loss = 0.804\nepoch 6: test ovo accuracy = 0.866\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:29<02:07,  3.37it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.794\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [00:59<01:37,  3.38it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.819\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [01:28<01:07,  3.39it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.887\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [01:58<00:38,  3.39it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.755\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [02:27<00:08,  3.38it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.786\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [02:36<00:00,  3.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [00:58<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 7: train ava accuracy = 0.763\nepoch 7: train loss = 0.789\nepoch 7: train ovo accuracy = 0.882\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [00:18<00:00,  8.96it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 7: test ava accuracy = 0.740\nepoch 7: test loss = 0.812\nepoch 7: test ovo accuracy = 0.878\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def precision_macro(conf_matrix):\n  #macro = averaged across precisions for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[:, i].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise precision and macro\n\ndef recall_macro(conf_matrix):\n  #macro = averaged across recalls for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[i, :].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise recall and macro\n\ndef precision_ovo(conf_matrix, one_label=0): #one_label -- the label of the class which is opposed to other ones\n  sub_matrix = conf_matrix[:, one_label]\n  denum = conf_matrix.sum() - sub_matrix.sum()\n  num = conf_matrix.sum() - sub_matrix.sum() - conf_matrix[one_label, :].sum() + conf_matrix[one_label, one_label]\n  return num/denum\ndef recall_ovo(conf_matrix, one_label=0):\n  return conf_matrix[one_label, one_label]/conf_matrix[one_label, :].sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:09:53.421825Z","iopub.execute_input":"2025-01-03T14:09:53.422123Z","iopub.status.idle":"2025-01-03T14:09:53.428917Z","shell.execute_reply.started":"2025-01-03T14:09:53.422079Z","shell.execute_reply":"2025-01-03T14:09:53.428057Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:09:53.430329Z","iopub.execute_input":"2025-01-03T14:09:53.430595Z","execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[{"name":"stderr","text":" 43%|████▎     | 7677/18019 [00:06<00:12, 840.03it/s] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def evaluation_epoch_test(model, loader):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y = chunk\n      pred = model(qx.to(device), ax.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      #total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': -1,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_results = evaluation_epoch_test(model1, test_loader)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"v2: precision_ovo, recall_ovo = (0.9707504510879517, 0.9477296471595764)\n\nv1: precision_ovo, recall_ovo = (0.9473173022270203, 0.8949313759803772)","metadata":{}},{"cell_type":"code","source":"mtx = test_results['conf_matrix']\nprecision_ovo(mtx).item(), recall_ovo(mtx).item() #v2","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v2: (([tensor(0.6849), tensor(0.7429), tensor(0.8725)], tensor(0.7668)),\n ([tensor(0.9477), tensor(0.7545), tensor(0.5211)], tensor(0.7411)))\n\nv1: (([tensor(0.7607), tensor(0.8228), tensor(0.7750)], tensor(0.7861)),\n ([tensor(0.8949), tensor(0.7158), tensor(0.7563)], tensor(0.7890)))","metadata":{}},{"cell_type":"code","source":"precision_macro(mtx), recall_macro(mtx) #v2","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mtx#v2","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mtx#v1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T14:45:02.616128Z","iopub.execute_input":"2025-01-02T14:45:02.616388Z","iopub.status.idle":"2025-01-02T14:45:02.629256Z","shell.execute_reply.started":"2025-01-02T14:45:02.616368Z","shell.execute_reply":"2025-01-02T14:45:02.628647Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"tensor([[5085.,  401.,  196.],\n        [ 843., 4768., 1050.],\n        [ 757.,  626., 4291.]])"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_hist['real_test_res'] = [test_results]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_python_types(results):\n  output = {}\n  output['training_loss_history'] = results['training_loss_history']\n  for x in ['train_epochs_res', 'test_epochs_res', 'real_test_res']:\n    if x in [y for y in results.keys()]:\n        output[x] = []\n        for hist_log in results[x]:\n          res = {}\n          res['accuracy_ava'] = hist_log['accuracy_ava'].item()\n          if 'loss' in [y for y in hist_log.keys()]:\n            res['loss'] = hist_log['loss']\n          res['accuracy_ovo'] = hist_log['accuracy_ovo'].item()\n          if 'conf_matrix' in [y for y in hist_log.keys()]:\n            res['conf_matrix'] = hist_log['conf_matrix'].tolist()\n          output[x].append(res)\n\n  return output","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open('retnet_train_val_res_v2.json', 'w') as f:\n    json.dump(to_python_types(train_hist), f)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-03T14:09:59.119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}