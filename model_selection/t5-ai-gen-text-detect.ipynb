{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10268139,"sourceType":"datasetVersion","datasetId":6352740}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torcheval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:33:07.947398Z","iopub.execute_input":"2025-01-12T11:33:07.947830Z","iopub.status.idle":"2025-01-12T11:33:14.533611Z","shell.execute_reply.started":"2025-01-12T11:33:07.947799Z","shell.execute_reply":"2025-01-12T11:33:14.532325Z"}},"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom transformers import T5Tokenizer, T5Model\n#from datasets import Dataset\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers.pipelines.pt_utils import KeyDataset\nfrom tqdm import tqdm\nimport pandas as pd\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:33:14.535200Z","iopub.execute_input":"2025-01-12T11:33:14.535541Z","iopub.status.idle":"2025-01-12T11:33:32.289797Z","shell.execute_reply.started":"2025-01-12T11:33:14.535514Z","shell.execute_reply":"2025-01-12T11:33:32.288816Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"torch.random.manual_seed(0)\ntokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\nmodel = T5Model.from_pretrained(\"t5-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:33:32.291968Z","iopub.execute_input":"2025-01-12T11:33:32.292788Z","iopub.status.idle":"2025-01-12T11:33:40.308844Z","shell.execute_reply.started":"2025-01-12T11:33:32.292752Z","shell.execute_reply":"2025-01-12T11:33:40.307691Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7b88486ba44d1799b5d5ba17249d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172623d2b7b34a6f87398f0a4d7a76b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5887db2de7400386a97b02547f3921"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf826d5c2fb248eda6de0cccfcf4423a"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:36:44.265712Z","iopub.execute_input":"2025-01-12T11:36:44.266069Z","iopub.status.idle":"2025-01-12T11:36:44.275605Z","shell.execute_reply.started":"2025-01-12T11:36:44.266042Z","shell.execute_reply":"2025-01-12T11:36:44.274429Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"T5Model(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\n\n\ndef enable_determinism():\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n    torch.use_deterministic_algorithms(True)\n\ndef fix_seeds(seed: int):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.mps.manual_seed(seed)\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\nenable_determinism()\nfix_seeds(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:33:40.310095Z","iopub.execute_input":"2025-01-12T11:33:40.310360Z","iopub.status.idle":"2025-01-12T11:33:40.322020Z","shell.execute_reply.started":"2025-01-12T11:33:40.310339Z","shell.execute_reply":"2025-01-12T11:33:40.320850Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_test_data = pd.read_csv('/kaggle/input/human-vs-qwen25-n-phi3/train_test_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T07:09:36.119716Z","iopub.execute_input":"2024-12-24T07:09:36.120186Z","iopub.status.idle":"2024-12-24T07:09:37.122058Z","shell.execute_reply.started":"2024-12-24T07:09:36.120148Z","shell.execute_reply":"2024-12-24T07:09:37.121358Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Класс датасета\nclass AnswersDataset(Dataset):\n  def __init__(self, tokenizer, data_df, sampletype,  max_len=512):\n    self.raw_data = data_df[data_df['sample_type']==sampletype]\n\n    self.max_len = max_len\n    self.tokenizer = tokenizer\n    self.inputs_q = []\n    self.inputs_a = []\n    self.targets = []\n\n    self.class_mapper = {'Human': 0, 'Phi3-mini': 1, 'Qwen25': 2}\n\n    self.class_mapper_inv = {v: k for k, v in self.class_mapper.items()}\n\n    self._build()\n\n\n  def __len__(self):\n    return len(self.inputs_a)\n\n  def __getitem__(self, index):\n    question_ids = self.inputs_q[index][\"input_ids\"].squeeze()\n    answers_ids = self.inputs_a[index][\"input_ids\"].squeeze()\n    target_ids = self.targets[index]\n\n    #src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n    #target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n\n    return  question_ids, answers_ids, target_ids\n    #{\"question_ids\": question_ids, \"answers_ids\": answers_ids, \"target_ids\": target_ids}\n\n  def _build(self):\n    self._buil_examples_from_files()\n\n  def _buil_examples_from_files(self):\n    # REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()]\")\n    # REPLACE_WITH_SPACE = re.compile(\"()|(\\-)|(\\/)\")\n\n    for i, row in tqdm(self.raw_data.iterrows(), total=self.raw_data.shape[0]):\n\n      if pd.isna(row['Answers']):\n        continue\n\n      text_question = row['Question']\n      text_answer = row['Answers']\n\n      line_question = text_question.strip()\n      line_answer = text_answer.strip()\n\n\n      # line = REPLACE_NO_SPACE.sub(\"\", line)\n      # line = REPLACE_WITH_SPACE.sub(\"\", line)\n      # line = line + ' '\n\n      target = self.class_mapper[row['Author']]\n\n       # tokenize inputs\n      tokenized_questions = self.tokenizer.batch_encode_plus(\n          [line_question], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      )\n\n      tokenized_answers = self.tokenizer.batch_encode_plus(\n          [line_answer], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      )\n\n       # tokenize targets\n\n\n      self.inputs_q.append(tokenized_questions)\n      self.inputs_a.append(tokenized_answers)\n\n      self.targets.append(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T07:06:59.705613Z","iopub.execute_input":"2024-12-24T07:06:59.705950Z","iopub.status.idle":"2024-12-24T07:06:59.713847Z","shell.execute_reply.started":"2024-12-24T07:06:59.705901Z","shell.execute_reply":"2024-12-24T07:06:59.713127Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"max_seq_length = 128 # with 256 one epoch with 2 evaluations take 2 hours together\ntrain_dataset = AnswersDataset(tokenizer, train_test_data, 'train', max_len=max_seq_length)\n#test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\nval_dataset = AnswersDataset(tokenizer, train_test_data, 'val', max_len=max_seq_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T07:06:59.714726Z","iopub.execute_input":"2024-12-24T07:06:59.715029Z","iopub.status.idle":"2024-12-24T07:08:47.374103Z","shell.execute_reply.started":"2024-12-24T07:06:59.715000Z","shell.execute_reply":"2024-12-24T07:08:47.373247Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 67699/67699 [01:21<00:00, 832.31it/s] \n100%|██████████| 21233/21233 [00:26<00:00, 808.38it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"g = torch.Generator()\nbatch_size=128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g,\n                          pin_memory=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T07:10:22.505530Z","iopub.execute_input":"2024-12-24T07:10:22.505825Z","iopub.status.idle":"2024-12-24T07:10:22.510487Z","shell.execute_reply.started":"2024-12-24T07:10:22.505804Z","shell.execute_reply":"2024-12-24T07:10:22.509609Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn as nn\nclass T5Clf_FCtuned(nn.Module):\n    def __init__(self, max_seq_length=512):\n        super(T5Clf_FCtuned, self).__init__()\n        self.t5model = model\n        self.decoder_out_features =  self.t5model.decoder.block[11].layer[2].DenseReluDense.wo.out_features\n        self.length=max_seq_length\n        self.fc = nn.Linear(in_features=self.length*self.decoder_out_features, out_features = 3)\n        self.activation = nn.Softmax()\n        self.freeze_layers()\n\n\n    def freeze_layers(self):\n      for param in self.t5model.parameters():\n        param.requires_grad = False\n\n\n\n    def forward(self, qx, ax):\n        out = self.t5model(\n            input_ids=qx,\n            decoder_input_ids=ax).last_hidden_state\n        out = out.view(out.shape[0], -1)\n        pred = self.fc(out)\n\n        return self.activation(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:33:40.323351Z","iopub.execute_input":"2025-01-12T11:33:40.323816Z","iopub.status.idle":"2025-01-12T11:33:40.340417Z","shell.execute_reply.started":"2025-01-12T11:33:40.323775Z","shell.execute_reply":"2025-01-12T11:33:40.338955Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.parameters()):\n        nn=1\n        for s in list(p.size()):\n            nn = nn*s\n        pp += nn\n    return pp\nmodel1 = T5Clf_FCtuned(max_seq_length)\nget_n_params(model1.t5model.shared)+get_n_params(model1.t5model.encoder)\\\n+get_n_params(model1.t5model.decoder)+get_n_params(model1.fc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T11:37:36.536850Z","iopub.execute_input":"2025-01-12T11:37:36.537211Z","iopub.status.idle":"2025-01-12T11:37:36.552944Z","shell.execute_reply.started":"2025-01-12T11:37:36.537185Z","shell.execute_reply":"2025-01-12T11:37:36.551954Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"272547075"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from torcheval.metrics.functional import multiclass_confusion_matrix as conf_matrix\n\ndef evaluation_epoch(model, loader, loss_obj):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y = chunk\n      pred = model(qx.to(device), ax.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': total_loss/n_total,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}\n\ndef train_neural_net(model, train_loader, test_loader, n_epochs=1):\n  loss = nn.CrossEntropyLoss()\n  optimizer=torch.optim.Adam(model.fc.parameters(), lr=1e-4)\n  loss_train_history = [] # логируется всегда\n\n  # логируются каждую эпоху\n\n  train_epoch_evals = []\n  test_epoch_evals = []\n\n  for _ in range(n_epochs):\n    i=0\n    model.train().to(device)\n    for train_chunk in tqdm(train_loader):\n        qx, ax, y = train_chunk\n        optimizer.zero_grad(set_to_none=True)\n\n\n        pred = model(qx.to(device), ax.to(device))\n        loss_val = loss(pred, y.to(device)) #.long()\n        loss_val.backward()\n\n        loss_val_item = loss_val.detach().cpu().item()\n\n        optimizer.step()\n        loss_train_history.append(loss_val_item)\n        i+=1\n        if i % 100 == 0:\n          print(f'train step {i}: train loss = {loss_val_item :.3f}')\n        \n\n    model.eval()\n    #model.cpu()\n\n    #train\n    print('train evaluation')\n    train_eval = evaluation_epoch(model, train_loader, loss)\n    print(f\"epoch {_}: train ava accuracy = {train_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: train loss = {train_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: train ovo accuracy = {train_eval['accuracy_ovo'] :.3f}\")\n    train_epoch_evals.append(train_eval)\n\n    #test\n    print('test evaluation')\n    test_eval = evaluation_epoch(model, test_loader, loss)\n    print(f\"epoch {_}: test ava accuracy = {test_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: test loss = {test_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: test ovo accuracy = {test_eval['accuracy_ovo'] :.3f}\")\n    test_epoch_evals.append(test_eval)\n\n  return {'training_loss_history': loss_train_history,\n          'train_epochs_res': train_epoch_evals,\n          'test_epochs_res': test_epoch_evals\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:01:06.509590Z","iopub.execute_input":"2024-12-24T08:01:06.509976Z","iopub.status.idle":"2024-12-24T08:01:06.520810Z","shell.execute_reply.started":"2024-12-24T08:01:06.509947Z","shell.execute_reply":"2024-12-24T08:01:06.519879Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"enable_determinism()\nfix_seeds(0)\nmodel1 = T5Clf_FCtuned(max_seq_length)\ntrain_hist = train_neural_net(model1, train_loader, val_loader, n_epochs=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:01:07.218092Z","iopub.execute_input":"2024-12-24T08:01:07.218432Z","iopub.status.idle":"2024-12-24T14:32:40.860611Z","shell.execute_reply.started":"2024-12-24T08:01:07.218401Z","shell.execute_reply":"2024-12-24T14:32:40.859656Z"}},"outputs":[{"name":"stderr","text":" 19%|█▉        | 100/529 [04:10<17:57,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.951\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:20<13:40,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.909\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:30<09:33,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.904\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:41<05:24,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.913\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:52<01:12,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.829\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:04<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:32<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: train ava accuracy = 0.678\nepoch 0: train loss = 0.868\nepoch 0: train ovo accuracy = 0.824\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:25<00:00,  2.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: test ava accuracy = 0.645\nepoch 0: test loss = 0.894\nepoch 0: test ovo accuracy = 0.824\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:10<17:52,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.818\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:20<13:43,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.902\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:30<09:32,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.859\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:40<05:23,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.866\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:50<01:12,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.840\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:03<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:31<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: train ava accuracy = 0.728\nepoch 1: train loss = 0.828\nepoch 1: train ovo accuracy = 0.843\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:26<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: test ava accuracy = 0.708\nepoch 1: test loss = 0.845\nepoch 1: test ovo accuracy = 0.841\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:09<17:56,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.893\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:18<13:39,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.846\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:29<09:32,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.854\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:39<05:21,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.782\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:49<01:12,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.883\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:01<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:28<00:00,  2.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: train ava accuracy = 0.740\nepoch 2: train loss = 0.810\nepoch 2: train ovo accuracy = 0.847\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:25<00:00,  2.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: test ava accuracy = 0.725\nepoch 2: test loss = 0.824\nepoch 2: test ovo accuracy = 0.843\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:08<17:45,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.844\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:16<13:35,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.800\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:25<09:32,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.847\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:36<05:22,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.857\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:45<01:12,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.858\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [21:56<00:00,  2.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:27<00:00,  2.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: train ava accuracy = 0.750\nepoch 3: train loss = 0.801\nepoch 3: train ovo accuracy = 0.854\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:26<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: test ava accuracy = 0.719\nepoch 3: test loss = 0.828\nepoch 3: test ovo accuracy = 0.847\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:08<17:55,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.860\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:20<13:48,  2.52s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.853\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:30<09:29,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.790\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:38<05:20,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.804\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:46<01:12,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.819\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [21:58<00:00,  2.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:22<00:00,  2.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: train ava accuracy = 0.759\nepoch 4: train loss = 0.794\nepoch 4: train ovo accuracy = 0.862\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:26<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: test ava accuracy = 0.732\nepoch 4: test loss = 0.817\nepoch 4: test ovo accuracy = 0.858\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:08<17:45,  2.48s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.811\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:18<13:42,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.808\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:28<09:32,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.834\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:38<05:22,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.782\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:47<01:12,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.844\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:00<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:33<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: train ava accuracy = 0.730\nepoch 5: train loss = 0.816\nepoch 5: train ovo accuracy = 0.861\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:26<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: test ava accuracy = 0.689\nepoch 5: test loss = 0.853\nepoch 5: test ovo accuracy = 0.861\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:09<17:52,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.835\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:19<13:41,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.784\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:29<09:34,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.813\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:39<05:20,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.795\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:48<01:12,  2.49s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.821\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:00<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:26<00:00,  2.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: train ava accuracy = 0.747\nepoch 6: train loss = 0.802\nepoch 6: train ovo accuracy = 0.859\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:22<00:00,  2.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: test ava accuracy = 0.709\nepoch 6: test loss = 0.835\nepoch 6: test ovo accuracy = 0.858\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [04:09<17:53,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.870\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [08:20<13:43,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.791\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [12:30<09:35,  2.51s/it]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.827\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [16:41<05:22,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.778\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [20:51<01:12,  2.50s/it]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.803\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [22:04<00:00,  2.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [20:34<00:00,  2.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"epoch 7: train ava accuracy = 0.749\nepoch 7: train loss = 0.799\nepoch 7: train ovo accuracy = 0.872\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [06:26<00:00,  2.33s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 7: test ava accuracy = 0.702\nepoch 7: test loss = 0.840\nepoch 7: test ovo accuracy = 0.865\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_hist","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:44:41.685179Z","iopub.execute_input":"2024-12-24T14:44:41.685511Z","iopub.status.idle":"2024-12-24T14:45:02.960000Z","shell.execute_reply.started":"2024-12-24T14:44:41.685483Z","shell.execute_reply":"2024-12-24T14:45:02.959228Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 18019/18019 [00:21<00:00, 848.48it/s]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!pip install torcheval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:50:03.263855Z","iopub.execute_input":"2024-12-24T14:50:03.264254Z","iopub.status.idle":"2024-12-24T14:50:06.446239Z","shell.execute_reply.started":"2024-12-24T14:50:03.264230Z","shell.execute_reply":"2024-12-24T14:50:06.445072Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from torcheval.metrics.functional import multiclass_confusion_matrix as conf_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:50:08.045244Z","iopub.execute_input":"2024-12-24T14:50:08.045604Z","iopub.status.idle":"2024-12-24T14:50:08.049755Z","shell.execute_reply.started":"2024-12-24T14:50:08.045574Z","shell.execute_reply":"2024-12-24T14:50:08.048855Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def evaluation_epoch_test(model, loader):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y =chunk\n      pred = model(qx.to(device), ax.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      #total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': -1,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:50:44.728287Z","iopub.execute_input":"2024-12-24T14:50:44.728601Z","iopub.status.idle":"2024-12-24T14:50:44.735394Z","shell.execute_reply.started":"2024-12-24T14:50:44.728579Z","shell.execute_reply":"2024-12-24T14:50:44.734536Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"test_results = evaluation_epoch_test(model1, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:51:33.682891Z","iopub.execute_input":"2024-12-24T14:51:33.683236Z","iopub.status.idle":"2024-12-24T14:57:02.535495Z","shell.execute_reply.started":"2024-12-24T14:51:33.683211Z","shell.execute_reply":"2024-12-24T14:57:02.534606Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 141/141 [05:28<00:00,  2.33s/it]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"mtx = test_results['conf_matrix']\nprecision_ovo(mtx).item(), recall_ovo(mtx).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:27:11.471550Z","iopub.execute_input":"2024-12-24T15:27:11.471847Z","iopub.status.idle":"2024-12-24T15:27:11.478566Z","shell.execute_reply.started":"2024-12-24T15:27:11.471826Z","shell.execute_reply":"2024-12-24T15:27:11.477858Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(0.9325045943260193, 0.8643083572387695)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"precision_macro(mtx), recall_macro(mtx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:27:22.861846Z","iopub.execute_input":"2024-12-24T15:27:22.862189Z","iopub.status.idle":"2024-12-24T15:27:22.871490Z","shell.execute_reply.started":"2024-12-24T15:27:22.862162Z","shell.execute_reply":"2024-12-24T15:27:22.870721Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(([tensor(0.7448), tensor(0.8638), tensor(0.6039)], tensor(0.7375)),\n ([tensor(0.8643), tensor(0.5017), tensor(0.8040)], tensor(0.7234)))"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"mtx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:27:30.712654Z","iopub.execute_input":"2024-12-24T15:27:30.712976Z","iopub.status.idle":"2024-12-24T15:27:30.718857Z","shell.execute_reply.started":"2024-12-24T15:27:30.712949Z","shell.execute_reply":"2024-12-24T15:27:30.718155Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"tensor([[4911.,  186.,  585.],\n        [ 912., 3342., 2407.],\n        [ 771.,  341., 4562.]])"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"def precision_macro(conf_matrix):\n  #macro = averaged across precisions for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[:, i].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise precision and macro\n\ndef recall_macro(conf_matrix):\n  #macro = averaged across recalls for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[i, :].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise recall and macro\n\ndef precision_ovo(conf_matrix, one_label=0): #one_label -- the label of the class which is opposed to other ones\n  sub_matrix = conf_matrix[:, one_label]\n  denum = conf_matrix.sum() - sub_matrix.sum()\n  num = conf_matrix.sum() - sub_matrix.sum() - conf_matrix[one_label, :].sum() + conf_matrix[one_label, one_label]\n  return num/denum\ndef recall_ovo(conf_matrix, one_label=0):\n  return conf_matrix[one_label, one_label]/conf_matrix[one_label, :].sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:26:34.539231Z","iopub.execute_input":"2024-12-24T15:26:34.539767Z","iopub.status.idle":"2024-12-24T15:26:34.549564Z","shell.execute_reply.started":"2024-12-24T15:26:34.539710Z","shell.execute_reply":"2024-12-24T15:26:34.548566Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def to_python_types(results):\n  output = {}\n  output['training_loss_history'] = results['training_loss_history']\n  for x in ['train_epochs_res', 'test_epochs_res', 'real_test_res']:\n    if x in [y for y in results.keys()]:\n        output[x] = []\n        for hist_log in results[x]:\n          res = {}\n          res['accuracy_ava'] = hist_log['accuracy_ava'].item()\n          if 'loss' in [y for y in hist_log.keys()]:\n            res['loss'] = hist_log['loss']\n          res['accuracy_ovo'] = hist_log['accuracy_ovo'].item()\n          if 'conf_matrix' in [y for y in hist_log.keys()]:\n            res['conf_matrix'] = hist_log['conf_matrix'].tolist()\n          output[x].append(res)\n\n  return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:26:36.449847Z","iopub.execute_input":"2024-12-24T15:26:36.450200Z","iopub.status.idle":"2024-12-24T15:26:36.455878Z","shell.execute_reply.started":"2024-12-24T15:26:36.450174Z","shell.execute_reply":"2024-12-24T15:26:36.454956Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"[y for y in train_hist.keys()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:46:40.711488Z","iopub.execute_input":"2024-12-22T14:46:40.711872Z","iopub.status.idle":"2024-12-22T14:46:40.717939Z","shell.execute_reply.started":"2024-12-22T14:46:40.711842Z","shell.execute_reply":"2024-12-22T14:46:40.717070Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['training_loss_history', 'train_epochs_res', 'test_epochs_res']"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"train_hist['real_test_res'] = [test_results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:27:54.614022Z","iopub.execute_input":"2024-12-24T15:27:54.614380Z","iopub.status.idle":"2024-12-24T15:27:54.618463Z","shell.execute_reply.started":"2024-12-24T15:27:54.614357Z","shell.execute_reply":"2024-12-24T15:27:54.617487Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#print(to_python_types(train_hist))\nimport json\nwith open('t5_train_val_res.json', 'w') as f:\n    json.dump(to_python_types(train_hist), f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:28:01.781421Z","iopub.execute_input":"2024-12-24T15:28:01.781711Z","iopub.status.idle":"2024-12-24T15:28:01.793770Z","shell.execute_reply.started":"2024-12-24T15:28:01.781690Z","shell.execute_reply":"2024-12-24T15:28:01.793017Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"test_results = evaluation_epoch_test(model1, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:49:55.848176Z","iopub.execute_input":"2024-12-22T14:49:55.848515Z","iopub.status.idle":"2024-12-22T14:54:54.797503Z","shell.execute_reply.started":"2024-12-22T14:49:55.848486Z","shell.execute_reply":"2024-12-22T14:54:54.796568Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 141/141 [04:58<00:00,  2.12s/it]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:55:18.951074Z","iopub.execute_input":"2024-12-22T14:55:18.951420Z","iopub.status.idle":"2024-12-22T14:55:18.959920Z","shell.execute_reply.started":"2024-12-22T14:55:18.951386Z","shell.execute_reply":"2024-12-22T14:55:18.959142Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'accuracy_ava': tensor(0.7228),\n 'loss': -1,\n 'accuracy_ovo': tensor(0.8760),\n 'conf_matrix': tensor([[3821.,  513., 1348.],\n         [ 212., 4265., 2184.],\n         [ 161.,  577., 4936.]])}"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"train_hist['real_test_res'] = [test_results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:55:34.285088Z","iopub.execute_input":"2024-12-22T14:55:34.285415Z","iopub.status.idle":"2024-12-22T14:55:34.289352Z","shell.execute_reply.started":"2024-12-22T14:55:34.285385Z","shell.execute_reply":"2024-12-22T14:55:34.288470Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"mtx = test_results['conf_matrix']\nprecision_ovo(mtx).item(), recall_ovo(mtx).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:57:52.511399Z","iopub.execute_input":"2024-12-22T14:57:52.511716Z","iopub.status.idle":"2024-12-22T14:57:52.517855Z","shell.execute_reply.started":"2024-12-22T14:57:52.511693Z","shell.execute_reply":"2024-12-22T14:57:52.517100Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(0.8653693199157715, 0.6724745035171509)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"precision_macro(mtx), recall_macro(mtx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:58:11.081215Z","iopub.execute_input":"2024-12-22T14:58:11.081550Z","iopub.status.idle":"2024-12-22T14:58:11.090681Z","shell.execute_reply.started":"2024-12-22T14:58:11.081519Z","shell.execute_reply":"2024-12-22T14:58:11.089754Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(([tensor(0.9111), tensor(0.7965), tensor(0.5829)], tensor(0.7635)),\n ([tensor(0.6725), tensor(0.6403), tensor(0.8699)], tensor(0.7276)))"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"with open('t5_train_val_test_res.json', 'w') as f:\n    json.dump(to_python_types(train_hist), f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:55:36.873890Z","iopub.execute_input":"2024-12-22T14:55:36.874232Z","iopub.status.idle":"2024-12-22T14:55:36.885035Z","shell.execute_reply.started":"2024-12-22T14:55:36.874208Z","shell.execute_reply":"2024-12-22T14:55:36.884313Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"#only train and val results\ncheck_read = None\nwith open('/kaggle/working/t5_train_val_test_res.json') as f:\n    check_read = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:56:30.376125Z","iopub.execute_input":"2024-12-22T14:56:30.376453Z","iopub.status.idle":"2024-12-22T14:56:30.382728Z","shell.execute_reply.started":"2024-12-22T14:56:30.376427Z","shell.execute_reply":"2024-12-22T14:56:30.381717Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"check_read['real_test_res']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T14:56:40.977596Z","iopub.execute_input":"2024-12-22T14:56:40.977950Z","iopub.status.idle":"2024-12-22T14:56:40.983254Z","shell.execute_reply.started":"2024-12-22T14:56:40.977921Z","shell.execute_reply":"2024-12-22T14:56:40.982490Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"[{'accuracy_ava': 0.7227618098258972,\n  'loss': -1,\n  'accuracy_ovo': 0.876006007194519,\n  'conf_matrix': [[3821.0, 513.0, 1348.0],\n   [212.0, 4265.0, 2184.0],\n   [161.0, 577.0, 4936.0]]}]"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}