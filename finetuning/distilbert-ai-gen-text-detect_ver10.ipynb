{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10268139,"sourceType":"datasetVersion","datasetId":6352740}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torcheval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:54:44.367126Z","iopub.execute_input":"2025-01-11T14:54:44.367485Z","iopub.status.idle":"2025-01-11T14:54:51.044826Z","shell.execute_reply.started":"2025-01-11T14:54:44.367453Z","shell.execute_reply":"2025-01-11T14:54:51.043748Z"}},"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom transformers import DistilBertTokenizer, DistilBertModel\n#from datasets import Dataset\n\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers.pipelines.pt_utils import KeyDataset\nfrom tqdm import tqdm\nimport pandas as pd\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:54:51.046174Z","iopub.execute_input":"2025-01-11T14:54:51.046491Z","iopub.status.idle":"2025-01-11T14:55:14.612489Z","shell.execute_reply.started":"2025-01-11T14:54:51.046455Z","shell.execute_reply":"2025-01-11T14:55:14.611824Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.random.manual_seed(0)\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:14.613914Z","iopub.execute_input":"2025-01-11T14:55:14.614457Z","iopub.status.idle":"2025-01-11T14:55:17.266838Z","shell.execute_reply.started":"2025-01-11T14:55:14.614431Z","shell.execute_reply":"2025-01-11T14:55:17.265889Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fef58ba255b49c38d59c3e40f56517e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4ec2855a2744874b568ab6fd100c82e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd4252d97cb43138e10e8d436cc6122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18bf5c21af34ee0a9d7bd4849a39d9d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d5e4c5a6e94476a104cae610bf2812"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:17.268179Z","iopub.execute_input":"2025-01-11T14:55:17.268414Z","iopub.status.idle":"2025-01-11T14:55:17.274342Z","shell.execute_reply.started":"2025-01-11T14:55:17.268394Z","shell.execute_reply":"2025-01-11T14:55:17.273473Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (ffn): FFN(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (activation): GELUActivation()\n        )\n        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.parameters()):\n        nn=1\n        for s in list(p.size()):\n            nn = nn*s\n        pp += nn\n    return pp\nn1, n2 = get_n_params(model.embeddings), get_n_params(model.transformer)\nn1, n2, n1+n2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:17.275580Z","iopub.execute_input":"2025-01-11T14:55:17.275903Z","iopub.status.idle":"2025-01-11T14:55:17.294244Z","shell.execute_reply.started":"2025-01-11T14:55:17.275870Z","shell.execute_reply":"2025-01-11T14:55:17.293647Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(23835648, 42527232, 66362880)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_test_data = pd.read_csv('/kaggle/input/human-vs-qwen25-n-phi3/train_test_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:17.295011Z","iopub.execute_input":"2025-01-11T14:55:17.295285Z","iopub.status.idle":"2025-01-11T14:55:19.404297Z","shell.execute_reply.started":"2025-01-11T14:55:17.295250Z","shell.execute_reply":"2025-01-11T14:55:19.403393Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\n\n\ndef enable_determinism():\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n    torch.use_deterministic_algorithms(True)\n\ndef fix_seeds(seed: int):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.mps.manual_seed(seed)\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\nenable_determinism()\nfix_seeds(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:19.405317Z","iopub.execute_input":"2025-01-11T14:55:19.405656Z","iopub.status.idle":"2025-01-11T14:55:19.417332Z","shell.execute_reply.started":"2025-01-11T14:55:19.405625Z","shell.execute_reply":"2025-01-11T14:55:19.416615Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Класс датасета\nclass AnswersDataset(Dataset):\n  def __init__(self, tokenizer, data_df, sampletype,  max_len=512):\n    self.raw_data = data_df[data_df['sample_type']==sampletype]\n\n    self.max_len = max_len\n    self.tokenizer = tokenizer\n    self.inputs_q = []\n    self.inputs_a = []\n    self.masks_q = []\n    self.masks_a = []\n    self.targets = []\n\n    self.class_mapper = {'Human': 0, 'Phi3-mini': 1, 'Qwen25': 2}\n\n    self.class_mapper_inv = {v: k for k, v in self.class_mapper.items()}\n\n    self._build()\n\n\n  def __len__(self):\n    return len(self.inputs_a)\n\n  def __getitem__(self, index):\n    question_ids = self.inputs_q[index].squeeze()\n    answers_ids = self.inputs_a[index].squeeze()\n\n    question_mask = self.masks_q[index].squeeze()\n    answer_mask = self.masks_a[index].squeeze()\n\n    target_ids = self.targets[index]\n\n    #src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n    #target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n\n    return  question_ids, answers_ids, target_ids, question_mask, answer_mask\n    #{\"question_ids\": question_ids, \"answers_ids\": answers_ids, \"target_ids\": target_ids}\n\n  def _build(self):\n    self._buil_examples_from_files()\n\n  def _buil_examples_from_files(self):\n    # REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()]\")\n    # REPLACE_WITH_SPACE = re.compile(\"()|(\\-)|(\\/)\")\n\n    for i, row in tqdm(self.raw_data.iterrows(), total=self.raw_data.shape[0]):\n\n      if pd.isna(row['Answers']):\n        continue\n\n      text_question = row['Question']\n      text_answer = row['Answers']\n\n      line_question = text_question.strip()\n      line_answer = text_answer.strip()\n\n\n      # line = REPLACE_NO_SPACE.sub(\"\", line)\n      # line = REPLACE_WITH_SPACE.sub(\"\", line)\n      # line = line + ' '\n\n      target = self.class_mapper[row['Author']]\n\n       # tokenize inputs\n      tokenized_questions, q_mask = [v for k, v in self.tokenizer.batch_encode_plus(\n          [line_question], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      ).items()]\n      tokenized_answers, a_mask = [v for k, v in self.tokenizer.batch_encode_plus(\n          [line_answer], max_length=self.max_len, padding='max_length', return_tensors=\"pt\",\n          truncation=True\n      ).items()]\n\n       # tokenize targets\n\n\n      self.inputs_q.append(tokenized_questions)\n      self.inputs_a.append(tokenized_answers)\n      self.masks_q.append(q_mask)\n      self.masks_a.append(a_mask)\n      self.targets.append(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:19.419439Z","iopub.execute_input":"2025-01-11T14:55:19.419689Z","iopub.status.idle":"2025-01-11T14:55:19.444232Z","shell.execute_reply.started":"2025-01-11T14:55:19.419668Z","shell.execute_reply":"2025-01-11T14:55:19.443424Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"max_seq_length = 128 # with 256 one epoch with 2 evaluations take 2 hours together\ntrain_dataset = AnswersDataset(tokenizer, train_test_data, 'train', max_len=max_seq_length)\n#test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\nval_dataset = AnswersDataset(tokenizer, train_test_data, 'val', max_len=max_seq_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:55:19.445354Z","iopub.execute_input":"2025-01-11T14:55:19.445676Z","iopub.status.idle":"2025-01-11T15:00:10.621032Z","shell.execute_reply.started":"2025-01-11T14:55:19.445645Z","shell.execute_reply":"2025-01-11T15:00:10.620041Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 67699/67699 [03:40<00:00, 307.37it/s]\n100%|██████████| 21233/21233 [01:10<00:00, 299.70it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"g = torch.Generator()\nbatch_size=128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g,\n                          pin_memory=True, num_workers=2, worker_init_fn=seed_worker)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2, worker_init_fn=seed_worker)\n#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T15:00:10.622121Z","iopub.execute_input":"2025-01-11T15:00:10.622476Z","iopub.status.idle":"2025-01-11T15:00:10.627585Z","shell.execute_reply.started":"2025-01-11T15:00:10.622439Z","shell.execute_reply":"2025-01-11T15:00:10.626687Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn as nn\nclass DistilBERTClf_FCtuned_v10(nn.Module):\n    def __init__(self, max_seq_length=512):\n        super(DistilBERTClf_FCtuned_v10, self).__init__()\n        self.dbmodel = model\n        # v1 one head of additional attention\n        # v2 two heads\n        # v3 three heads\n        # v4 one head, no dropout in the foremost attention\n        # v5 GELU between FC and the attention\n        # v6 one head, 0.2 dropout in the foremost attention\n        # v7 ELU between FC and the attention (and 0.2 dropout)\n        # v8 combination of 2 best (in precision and recall OvR): +2 heads and GELU\n        # v9 ELU between FC and the attention\n        self.model_out_features =  self.dbmodel.transformer.layer[-1].ffn.lin2.out_features\n        self.attention_layer = nn.MultiheadAttention(embed_dim=self.model_out_features,\n                                                     num_heads=3, dropout=0.1, batch_first=True)\n        self.length=max_seq_length\n        self.fc = nn.Linear(in_features=self.length*self.model_out_features, out_features = 3)\n        self.activation_inner = nn.GELU()\n        self.activation = nn.Softmax(dim=1)\n        self.freeze_layers()\n\n\n    def freeze_layers(self):\n      for param in self.dbmodel.parameters():\n        param.requires_grad = False\n\n\n\n    def forward(self, qx, ax, qmask, amask):\n        #qout = self.dbmodel(input_ids=qx, attention_mask=qmask).last_hidden_state\n        aout = self.dbmodel(input_ids=ax, attention_mask=amask).last_hidden_state\n        out, out_weights = self.attention_layer(aout, aout, aout)\n        out = out.reshape(out.shape[0], -1) \n        out = self.activation_inner(out)\n        pred = self.fc(out)\n\n        return self.activation(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T15:00:10.628518Z","iopub.execute_input":"2025-01-11T15:00:10.628870Z","iopub.status.idle":"2025-01-11T15:00:10.649053Z","shell.execute_reply.started":"2025-01-11T15:00:10.628837Z","shell.execute_reply":"2025-01-11T15:00:10.648156Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from torcheval.metrics.functional import multiclass_confusion_matrix as conf_matrix\n\ndef evaluation_epoch(model, loader, loss_obj):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y, qmask, amask = chunk\n      pred = model(qx.to(device), ax.to(device), qmask.to(device), amask.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': total_loss/n_total,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}\n\ndef train_neural_net(model, train_loader, test_loader):\n  loss = nn.CrossEntropyLoss()\n  optimizer=torch.optim.Adam([{'params': model.attention_layer.parameters()},\n                              {'params': model.fc.parameters()}], lr=1e-4)\n  n_epochs=8\n  loss_train_history = [] # логируется всегда\n\n  # логируются каждую эпоху\n\n  train_epoch_evals = []\n  test_epoch_evals = []\n\n  for _ in range(n_epochs):\n    i=0\n    model.train().to(device)\n    for train_chunk in tqdm(train_loader):\n        qx, ax, y, qmask, amask = train_chunk\n        optimizer.zero_grad(set_to_none=True)\n\n\n        pred = model(qx.to(device), ax.to(device), qmask.to(device), amask.to(device))\n        loss_val = loss(pred, y.to(device)) #.long()\n        loss_val.backward()\n\n        loss_val_item = loss_val.detach().cpu().item()\n\n        optimizer.step()\n        loss_train_history.append(loss_val_item)\n        i+=1\n        if i % 100 == 0:\n          print(f'train step {i}: train loss = {loss_val_item :.3f}')\n        #break\n\n    model.eval()\n    #model.cpu()\n\n    #train\n    print('train evaluation')\n    train_eval = evaluation_epoch(model, train_loader, loss)\n    print(f\"epoch {_}: train ava accuracy = {train_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: train loss = {train_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: train ovo accuracy = {train_eval['accuracy_ovo'] :.3f}\")\n    train_epoch_evals.append(train_eval)\n\n    #test\n    print('test evaluation')\n    test_eval = evaluation_epoch(model, test_loader, loss)\n    print(f\"epoch {_}: test ava accuracy = {test_eval['accuracy_ava'] :.3f}\")\n    print(f\"epoch {_}: test loss = {test_eval['loss'] :.3f}\")\n    print(f\"epoch {_}: test ovo accuracy = {test_eval['accuracy_ovo'] :.3f}\")\n    test_epoch_evals.append(test_eval)\n\n  return {'training_loss_history': loss_train_history,\n          'train_epochs_res': train_epoch_evals,\n          'test_epochs_res': test_epoch_evals\n          }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T15:00:10.649954Z","iopub.execute_input":"2025-01-11T15:00:10.650245Z","iopub.status.idle":"2025-01-11T15:00:12.115125Z","shell.execute_reply.started":"2025-01-11T15:00:10.650216Z","shell.execute_reply":"2025-01-11T15:00:12.114138Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"enable_determinism()\nfix_seeds(0)\n\nmodel1 = DistilBERTClf_FCtuned_v10(max_seq_length) \ntrain_hist = train_neural_net(model1, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T15:00:12.116076Z","iopub.execute_input":"2025-01-11T15:00:12.116369Z","iopub.status.idle":"2025-01-11T16:25:22.757952Z","shell.execute_reply.started":"2025-01-11T15:00:12.116346Z","shell.execute_reply":"2025-01-11T16:25:22.757014Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/529 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n 19%|█▉        | 100/529 [00:51<03:39,  1.96it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.840\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:44<03:00,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.779\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:40<02:06,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.836\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:35<01:12,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.722\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:31<00:16,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.744\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:47<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: train ava accuracy = 0.777\nepoch 0: train loss = 0.767\nepoch 0: train ovo accuracy = 0.905\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 0: test ava accuracy = 0.749\nepoch 0: test loss = 0.794\nepoch 0: test ovo accuracy = 0.903\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:57,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.724\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:02,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.763\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:46<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.735\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.753\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:37<00:16,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.797\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:54<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: train ava accuracy = 0.810\nepoch 1: train loss = 0.737\nepoch 1: train ovo accuracy = 0.917\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1: test ava accuracy = 0.787\nepoch 1: test loss = 0.757\nepoch 1: test ovo accuracy = 0.917\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:58,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.737\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:03,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.686\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:46<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.719\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.741\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:38<00:16,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.744\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:54<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:23<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: train ava accuracy = 0.832\nepoch 2: train loss = 0.715\nepoch 2: train ovo accuracy = 0.925\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2: test ava accuracy = 0.815\nepoch 2: test loss = 0.731\nepoch 2: test ovo accuracy = 0.923\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:58,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.743\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:02,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.699\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:46<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.735\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:41<01:11,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.692\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:37<00:16,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.691\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:53<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:23<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: train ava accuracy = 0.841\nepoch 3: train loss = 0.706\nepoch 3: train ovo accuracy = 0.930\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3: test ava accuracy = 0.824\nepoch 3: test loss = 0.722\nepoch 3: test ovo accuracy = 0.927\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:58,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.720\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:02,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.672\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:46<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.704\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.712\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:38<00:16,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.713\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:54<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:23<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: train ava accuracy = 0.845\nepoch 4: train loss = 0.702\nepoch 4: train ovo accuracy = 0.924\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4: test ava accuracy = 0.823\nepoch 4: test loss = 0.725\nepoch 4: test ovo accuracy = 0.921\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:58,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.694\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:03,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.752\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:47<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.687\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.761\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:38<00:16,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.692\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:54<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: train ava accuracy = 0.857\nepoch 5: train loss = 0.691\nepoch 5: train ovo accuracy = 0.932\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5: test ava accuracy = 0.833\nepoch 5: test loss = 0.714\nepoch 5: test ovo accuracy = 0.926\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:59,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.686\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:02,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.696\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:46<02:06,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.730\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.721\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:37<00:16,  1.81it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.736\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:53<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: train ava accuracy = 0.854\nepoch 6: train loss = 0.694\nepoch 6: train ovo accuracy = 0.931\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6: test ava accuracy = 0.821\nepoch 6: test loss = 0.727\nepoch 6: test ovo accuracy = 0.925\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 100/529 [00:55<03:59,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 100: train loss = 0.656\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 200/529 [01:51<03:03,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 200: train loss = 0.705\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 300/529 [02:47<02:07,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 300: train loss = 0.734\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 400/529 [03:42<01:11,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"train step 400: train loss = 0.649\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▍| 500/529 [04:38<00:16,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"train step 500: train loss = 0.724\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:54<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 529/529 [04:22<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 7: train ava accuracy = 0.850\nepoch 7: train loss = 0.697\nepoch 7: train ovo accuracy = 0.932\ntest evaluation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 166/166 [01:22<00:00,  2.01it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 7: test ava accuracy = 0.821\nepoch 7: test loss = 0.725\nepoch 7: test ovo accuracy = 0.929\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def precision_macro(conf_matrix):\n  #macro = averaged across precisions for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[:, i].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise precision and macro\n\ndef recall_macro(conf_matrix):\n  #macro = averaged across recalls for each class\n  n_classes = conf_matrix.shape[0]\n  by_class = []\n  for i in range(n_classes):\n    val = conf_matrix[i, i]/conf_matrix[i, :].sum()\n    by_class.append(val)\n  return by_class, sum(by_class)/n_classes # class-wise recall and macro\n\ndef precision_ovo(conf_matrix, one_label=0): #one_label -- the label of the class which is opposed to other ones\n  sub_matrix = conf_matrix[:, one_label]\n  denum = conf_matrix.sum() - sub_matrix.sum()\n  num = conf_matrix.sum() - sub_matrix.sum() - conf_matrix[one_label, :].sum() + conf_matrix[one_label, one_label]\n  return num/denum\ndef recall_ovo(conf_matrix, one_label=0):\n  return conf_matrix[one_label, one_label]/conf_matrix[one_label, :].sum()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:25:47.371306Z","iopub.execute_input":"2025-01-11T16:25:47.371639Z","iopub.status.idle":"2025-01-11T16:25:47.378307Z","shell.execute_reply.started":"2025-01-11T16:25:47.371613Z","shell.execute_reply":"2025-01-11T16:25:47.377375Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def to_python_types(results):\n  output = {}\n  output['training_loss_history'] = results['training_loss_history']\n  for x in ['train_epochs_res', 'test_epochs_res', 'real_test_res']:\n    if x in [y for y in results.keys()]:\n        output[x] = []\n        for hist_log in results[x]:\n          res = {}\n          res['accuracy_ava'] = hist_log['accuracy_ava'].item()\n          if 'loss' in [y for y in hist_log.keys()]:\n            res['loss'] = hist_log['loss']\n          res['accuracy_ovo'] = hist_log['accuracy_ovo'].item()\n          if 'conf_matrix' in [y for y in hist_log.keys()]:\n            res['conf_matrix'] = hist_log['conf_matrix'].tolist()\n          output[x].append(res)\n\n  return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:25:50.454900Z","iopub.execute_input":"2025-01-11T16:25:50.455214Z","iopub.status.idle":"2025-01-11T16:25:50.461349Z","shell.execute_reply.started":"2025-01-11T16:25:50.455188Z","shell.execute_reply":"2025-01-11T16:25:50.460434Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"test_dataset = AnswersDataset(tokenizer, train_test_data, 'test', max_len=max_seq_length)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n                        pin_memory=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:25:51.041988Z","iopub.execute_input":"2025-01-11T16:25:51.042285Z","iopub.status.idle":"2025-01-11T16:26:45.919471Z","shell.execute_reply.started":"2025-01-11T16:25:51.042262Z","shell.execute_reply":"2025-01-11T16:26:45.918478Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 18019/18019 [00:54<00:00, 328.60it/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def evaluation_epoch_test(model, loader):\n  n_correct, n_total = 0, 0\n  n_correct_oo = 0\n  total_loss = 0\n\n  total_conf_matrix = torch.zeros(size=(3, 3))\n\n  with torch.no_grad():\n    for chunk in tqdm(loader):\n      qx, ax, y, qmask, amask = chunk\n      pred = model(qx.to(device), ax.to(device), qmask.to(device), amask.to(device)).cpu()\n      apred = torch.argmax(pred, 1) # for all-vs-all classification\n\n      oopred = torch.where(apred > 0, 1, 0) # for one-vs-others classification\n      ooy = torch.where(y > 0, 1, 0)\n\n      n_correct += (apred == y).sum()\n      n_correct_oo += (oopred == ooy).sum()\n\n      n_total += y.shape[0]\n\n      #total_loss += y.shape[0] * loss_obj(pred, y).item()\n      total_conf_matrix+=conf_matrix(apred, y, num_classes=3)\n\n  return {'accuracy_ava': n_correct/n_total, 'loss': -1,\n          'accuracy_ovo':n_correct_oo/n_total, 'conf_matrix': total_conf_matrix}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:26:45.920488Z","iopub.execute_input":"2025-01-11T16:26:45.920806Z","iopub.status.idle":"2025-01-11T16:26:45.927258Z","shell.execute_reply.started":"2025-01-11T16:26:45.920769Z","shell.execute_reply":"2025-01-11T16:26:45.926482Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"test_results = evaluation_epoch_test(model1, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:26:45.928428Z","iopub.execute_input":"2025-01-11T16:26:45.928707Z","iopub.status.idle":"2025-01-11T16:27:56.611873Z","shell.execute_reply.started":"2025-01-11T16:26:45.928672Z","shell.execute_reply":"2025-01-11T16:27:56.610845Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 141/141 [01:10<00:00,  2.00it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"mtx = test_results['conf_matrix']\nprecision_ovo(mtx).item(), recall_ovo(mtx).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:27:56.613911Z","iopub.execute_input":"2025-01-11T16:27:56.614157Z","iopub.status.idle":"2025-01-11T16:27:56.621433Z","shell.execute_reply.started":"2025-01-11T16:27:56.614135Z","shell.execute_reply":"2025-01-11T16:27:56.620762Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(0.9508571624755859, 0.8940513730049133)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"mtx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:27:56.622201Z","iopub.execute_input":"2025-01-11T16:27:56.622485Z","iopub.status.idle":"2025-01-11T16:27:56.673263Z","shell.execute_reply.started":"2025-01-11T16:27:56.622454Z","shell.execute_reply":"2025-01-11T16:27:56.672519Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([[5080.,  162.,  440.],\n        [ 405., 4848., 1408.],\n        [ 282.,  428., 4964.]])"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"precision_macro(mtx), recall_macro(mtx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:27:56.674002Z","iopub.execute_input":"2025-01-11T16:27:56.674206Z","iopub.status.idle":"2025-01-11T16:27:56.682026Z","shell.execute_reply.started":"2025-01-11T16:27:56.674188Z","shell.execute_reply":"2025-01-11T16:27:56.681351Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(([tensor(0.8809), tensor(0.8915), tensor(0.7287)], tensor(0.8337)),\n ([tensor(0.8941), tensor(0.7278), tensor(0.8749)], tensor(0.8322)))"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_hist['real_test_res'] = [test_results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:27:56.682826Z","iopub.execute_input":"2025-01-11T16:27:56.683180Z","iopub.status.idle":"2025-01-11T16:27:56.692616Z","shell.execute_reply.started":"2025-01-11T16:27:56.683143Z","shell.execute_reply":"2025-01-11T16:27:56.691982Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_hist['real_test_res']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T18:08:23.578264Z","iopub.execute_input":"2025-01-07T18:08:23.578558Z","iopub.status.idle":"2025-01-07T18:08:23.585410Z","shell.execute_reply.started":"2025-01-07T18:08:23.578536Z","shell.execute_reply":"2025-01-07T18:08:23.584584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"to_python_types(train_hist)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T22:12:37.052343Z","iopub.execute_input":"2024-12-23T22:12:37.052625Z","iopub.status.idle":"2024-12-23T22:12:37.067848Z","shell.execute_reply.started":"2024-12-23T22:12:37.052604Z","shell.execute_reply":"2024-12-23T22:12:37.067137Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open('distilbert_train_val_res_v10.json', 'w') as f:\n    json.dump(to_python_types(train_hist), f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T16:27:56.694243Z","iopub.execute_input":"2025-01-11T16:27:56.694448Z","iopub.status.idle":"2025-01-11T16:27:56.716857Z","shell.execute_reply.started":"2025-01-11T16:27:56.694430Z","shell.execute_reply":"2025-01-11T16:27:56.716127Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}